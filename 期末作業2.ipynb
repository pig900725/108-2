{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讀入資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "(x_train, y_train0), (x_test, y_test0) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / x_train.max()\n",
    "x_test = x_test / x_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train0, 10)\n",
    "y_test = to_categorical(y_test0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 檢視測試資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(x_train.shape[0])\n",
    "x_sample = x_train[idx]\n",
    "y_sample = y_train0[idx].squeeze()\n",
    "\n",
    "plt.imshow(x_sample)\n",
    "plt.title(name_list[y_sample])\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立分類cifar10的卷積神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_layers = [Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu', name='Conv_1'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(128, (3, 3), padding='same', activation='relu', name='Conv_2'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(512, (3, 3), padding='same', activation='relu', name='Conv_3'),\n",
    "              GlobalAveragePooling2D()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC_layers = [Dense(units=256, activation='relu'),\n",
    "             Dense(units=10, activation='softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x1028f1350>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x10339a5d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1028f1910>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x1028f1e50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x10290d110>,\n",
       " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x10290d650>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1028f10d0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x10290d850>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_layers + FC_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 16, 16, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 8, 8, 512)         590336    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 762,122\n",
      "Trainable params: 762,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(CNN_layers+FC_layers)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "                optimizer=Adam(),\n",
    "                metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 295s 6ms/sample - loss: 1.7860 - categorical_accuracy: 0.3238 - val_loss: 1.5820 - val_categorical_accuracy: 0.4214\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 260s 5ms/sample - loss: 1.4279 - categorical_accuracy: 0.4720 - val_loss: 1.3524 - val_categorical_accuracy: 0.4999\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 267s 5ms/sample - loss: 1.2536 - categorical_accuracy: 0.5437 - val_loss: 1.1645 - val_categorical_accuracy: 0.5800\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 269s 5ms/sample - loss: 1.1303 - categorical_accuracy: 0.5917 - val_loss: 1.0893 - val_categorical_accuracy: 0.6065\n",
      "Epoch 5/5\n",
      " 9856/50000 [====>.........................] - ETA: 3:06 - loss: 1.0836 - categorical_accuracy: 0.6092"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "          batch_size=128, \n",
    "          epochs=5,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train = model.evaluate(x_train, y_train)\n",
    "score_test = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 遷移學習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讀入資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "(x_train2, y_train2), (x_test2, y_test2) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2 = x_train2.reshape(60000, 28, 28, 1)/255\n",
    "x_test2 = x_test2.reshape(10000, 28, 28, 1)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2 = to_categorical(y_train2, 10)\n",
    "y_test2 = to_categorical(y_test2, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 開函數學習機"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D \n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_layer2 = [Conv2D(16, (3, 3), input_shape=(28, 28, 1), padding='same', activation='relu', name='Conv_1'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(32, (3, 3), padding='same', activation='relu', name='Conv_2'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(64, (3, 3), padding='same', activation='relu', name='Conv_3'),\n",
    "              GlobalAveragePooling2D()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC_layer2 = [Dense(units=256, activation='relu'),\n",
    "             Dense(units=10, activation='softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential(CNN_layer2+FC_layer2)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', \n",
    "               optimizer=Adam(), \n",
    "               metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(x_train2, y_train2,\n",
    "           batch_size=256,\n",
    "           epochs=10, \n",
    "           validation_data=(x_test2, y_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train = model2.evaluate(x_train2, y_train2)\n",
    "score_test = model2.evaluate(x_test2, y_test2)\n",
    "\n",
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
